{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset of sign language digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset link : \n",
    "https://iiitaphyd-my.sharepoint.com/:f:/g/personal/apurva_jadhav_students_iiit_ac_in/Eictt5_qmoxNqezgQQiMWeIBph4sxlfA6jWAJNPnV2SF9Q?e=mQmYN0 \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l = np.load(\"X.npy\") # image\n",
    "y_l = np.load(\"Y.npy\") # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. You are provided with the dataset of sign language digits. Implement logistic regression from scratch to classify the images provided in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset and perform splitting into training and test sets with 70:30 ratio randomly using test train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_l = np.argmax(y_l, axis=1)\n",
    "\n",
    "max_ele = np.max(x_l)\n",
    "min_ele = np.min(x_l)\n",
    "\n",
    "x_l = ((x_l-min_ele)/(max_ele-min_ele)).reshape([x_l.shape[0], x_l.shape[1]* x_l.shape[2]])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_l, y_l, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plot a diagram for the sigmoid function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sigmoid = range(-25,25)\n",
    "y_sigmoid = []\n",
    "\n",
    "for i in x_sigmoid:\n",
    "    y_sigmoid.append(1 / (1 + np.exp(-i)))\n",
    "\n",
    "plt.plot(x_sigmoid, y_sigmoid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is used for binary classication. How do you modify it for multilabel dataset classification problems? State and Explain the methods used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification vs. Multi-class classification\n",
    "\n",
    "#### Binary Classification\n",
    "- thare are only two class present in the dataset \n",
    "- This kind of data require only one classifier to classify\n",
    "- Accuracy and Confusion Matrixare easy to derive and understand as there are only classes are present.\n",
    "\n",
    "Example:- Check person will servive or not from the titanic dataset\n",
    "\n",
    "\n",
    "#### Multi-class Classification\n",
    "- More than two classeswill be there in the dataset\n",
    "- Claasification model will be depend on claasification technique\n",
    "\t- one vs one: n*(n-1)/2\n",
    "\t- one vs all: n\n",
    "\n",
    "- Accuracy and Confusion Matrixare easy to derive,butit is difficult understand as there are only classes are present.\n",
    "- Example: Predicting animal as dog or cat or lion or tiger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-vs-All \n",
    "- If there are N classes present then will make N model by selecting one class vs all other classes as one class\n",
    "- we'll make sure one class will be given value as 1.\n",
    "\n",
    "\n",
    "- For Green vs Blue vs Red exaple\n",
    "\n",
    "- Classifier 1:- [Green] vs [Red, Blue]\n",
    "- Classifier 2:- [Blue] vs [Green, Red]\n",
    "- Classifier 3:- [Red] vs [Blue, Green]\n",
    "\n",
    "###### Classification:\n",
    "\n",
    "- binary classifier models predict the probability of correspondence with concerning classes\n",
    "- Final class will be, the class in which we get highest accuracy among those N binary model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-vs-one \n",
    "- If there are N classes present then will make N*(N-1) model by selecting each pair from that N classes.\n",
    "\n",
    "- For Green vs Blue vs Red vs White\n",
    "\n",
    "- Classifier 1:- [Green] vs [Blue]\n",
    "- Classifier 2:- [Green] vs [Red]\n",
    "- Classifier 3:- [Green] vs [White]\n",
    "- Classifier 4:- [Blue] vs [Red]\n",
    "- Classifier 5:- [Blue] vs [White]\n",
    "- Classifier 6:- [Red] vs [White]\n",
    "\n",
    "##### Classification:\n",
    "\n",
    "- for each data point, we'll classify with all model.\n",
    "- Then we'll sum the class prediction for that data point\n",
    "- And final data point is classifies to the class which has highest count among them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use both one vs all and one vs one method for the above problem statement purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_vs_all:\n",
    "    def __init__(self, total_features, total_classes, bias=True):\n",
    "        \n",
    "        self.total_features = total_features\n",
    "        self.bias = bias\n",
    "        if self.bias==True:\n",
    "            self.total_features += 1\n",
    "\n",
    "        self.total_classes = total_classes\n",
    "\n",
    "        self.weights = np.ones(self.total_features*self.total_classes).reshape((self.total_classes,self.total_features,1))\n",
    "\n",
    "    def save_weights(self):\n",
    "        file_name = \"weights_ova.npy\"\n",
    "        with open(file_name, 'wb') as f:\n",
    "            np.save(f, self.weights)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        file_name = \"weights_ova.npy\"\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.weights = np.load(f)\n",
    "\n",
    "    def train(self, X_train, Y_train, Transfer_learning=False, epoch=5000, alpha=0.01):\n",
    "\n",
    "        self.epoch = epoch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        if Transfer_learning == True:\n",
    "            self.load_weights()   \n",
    "\n",
    "        # print(\"\\nTrain :: \")\n",
    "\n",
    "        X_train = np.c_[X_train, np.ones(X_train.shape[0])]\n",
    "        m = X_train.shape[0]\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "            # print(\"\\n\", i, \"vs\" ,\"All:\")\n",
    "\n",
    "            new_Y_train = [1 if Y_train[idx] == i else 0 for idx in range(m)]\n",
    "            new_Y_train = np.array(new_Y_train)\n",
    "            new_Y_train = new_Y_train.reshape((-1,1))\n",
    "\n",
    "            # for _ in tqdm(range(self.epoch)):\n",
    "            for _ in range(self.epoch):\n",
    "                \n",
    "                xw = np.matmul(X_train, self.weights[i])\n",
    "                neg_xw = -1 * xw\n",
    "\n",
    "                hw_xw = 1 / (1 + np.exp(neg_xw))\n",
    "                dj_dw = np.matmul(X_train.T, (hw_xw - new_Y_train))/m\n",
    "                                \n",
    "                self.weights[i] = self.weights[i] - (self.alpha*dj_dw)  \n",
    "\n",
    "        self.save_weights()        \n",
    "\n",
    "    def test(self, X_test, Y_test):\n",
    "        # print(\"\\nTest :: \")\n",
    "\n",
    "        X_test = np.c_[X_test, np.ones(X_test.shape[0])]\n",
    "        m = X_test.shape[0]\n",
    "\n",
    "        class_percent = []\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):         \n",
    "            xw = np.matmul(X_test, self.weights[i])\n",
    "            neg_xw = -1 * xw\n",
    "\n",
    "            hw_xw = 1 / (1 + np.exp(neg_xw))\n",
    "            \n",
    "            class_percent.append(hw_xw)\n",
    "\n",
    "        class_percent = np.array(class_percent).T.reshape([m,self.total_classes])\n",
    "        Y_pred = np.argmax(class_percent, axis=1)\n",
    "\n",
    "        true_count = 0\n",
    "        for i in range(m):\n",
    "            if Y_pred[i] == Y_test[i]:\n",
    "                true_count += 1\n",
    "        \n",
    "        accu = true_count/ m\n",
    "        return accu, confusion_matrix(Y_test, Y_pred), classification_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_vs_one:\n",
    "    def __init__(self, total_features, total_classes, bias=True):\n",
    "        \n",
    "        self.total_features = total_features\n",
    "        self.bias = bias\n",
    "        if self.bias==True:\n",
    "            self.total_features += 1\n",
    "\n",
    "        self.total_classes = total_classes\n",
    "\n",
    "        count = int((self.total_classes * (self.total_classes-1))/2)\n",
    "        self.weights = np.ones(self.total_features*count).reshape((count,self.total_features,1))\n",
    "\n",
    "    def save_weights(self):\n",
    "        file_name = \"weights_ovo.npy\"\n",
    "        with open(file_name, 'wb') as f:\n",
    "            np.save(f, self.weights)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        file_name = \"weights_ovo.npy\"\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.weights = np.load(f)\n",
    "\n",
    "    def train(self, X_train, Y_train, Transfer_learning=False, epoch=5000, alpha=0.01):\n",
    "\n",
    "        self.epoch = epoch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        if Transfer_learning == True:\n",
    "            self.load_weights()   \n",
    "\n",
    "        # print(\"\\nTrain :: \")\n",
    "\n",
    "        X_train = np.c_[X_train, np.ones(X_train.shape[0])]\n",
    "        total_count = X_test.shape[0]\n",
    "\n",
    "        weight_idx = 0\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "            for j in range(i+1, self.total_classes):\n",
    "                # print(\"\\n\", i, \"vs\" , j ,\"::\")\n",
    "\n",
    "                new_X_train = [X_train[idx] for idx in range(total_count) if (Y_train[idx] == i or Y_train[idx] == j)]\n",
    "                new_X_train = np.array(new_X_train)\n",
    "                \n",
    "                m = new_X_train.shape[0]\n",
    "\n",
    "                new_Y_train = [Y_train[idx] for idx in range(total_count) if (Y_train[idx] == i or Y_train[idx] == j)]\n",
    "                 \n",
    "                new_Y_train = [1 if new_Y_train[idx] == i else 0 for idx in range(m)]\n",
    "                new_Y_train = np.array(new_Y_train)\n",
    "                new_Y_train = new_Y_train.reshape((-1,1))\n",
    "\n",
    "                # for _ in tqdm(range(self.epoch)):\n",
    "                for _ in range(self.epoch):\n",
    "                    \n",
    "                    xw = np.matmul(new_X_train, self.weights[weight_idx])\n",
    "                    neg_xw = -1 * xw\n",
    "\n",
    "                    hw_xw = 1 / (1 + np.exp(neg_xw))\n",
    "                    dj_dw = np.matmul(new_X_train.T, (hw_xw - new_Y_train))/m\n",
    "                                    \n",
    "                    self.weights[weight_idx] = self.weights[weight_idx] - (self.alpha*dj_dw)  \n",
    "\n",
    "                weight_idx += 1\n",
    "\n",
    "        self.save_weights()        \n",
    "\n",
    "    def test(self, X_test, Y_test):\n",
    "        # print(\"\\nTest :: \")\n",
    "\n",
    "        X_test = np.c_[X_test, np.ones(X_test.shape[0])]\n",
    "        m = X_test.shape[0]\n",
    "\n",
    "        class_pred = []\n",
    "\n",
    "        weight_idx = 0\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "            for j in range(i+1, self.total_classes):   \n",
    "                \n",
    "                xw = np.matmul(X_test, self.weights[weight_idx])\n",
    "                neg_xw = -1 * xw\n",
    "\n",
    "                hw_xw = 1 / (1 + np.exp(neg_xw))\n",
    "                \n",
    "                onevsone_class_pred = [i if hw_xw[idx]>=0.5 else j for idx in range(m)] \n",
    "                class_pred.append(onevsone_class_pred)\n",
    "\n",
    "                weight_idx += 1\n",
    "\n",
    "        class_pred = np.array(class_pred)        \n",
    "        Y_pred = stats.mode(class_pred)[0][0]\n",
    "\n",
    "        true_count = 0\n",
    "        for i in range(m):\n",
    "            if Y_pred[i] == Y_test[i]:\n",
    "                true_count += 1\n",
    "        \n",
    "        accu = true_count/ m\n",
    "        return accu, confusion_matrix(Y_test, Y_pred), classification_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Also get results using Log Reg from scikit learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_vs_all_sklearn:\n",
    "    def __init__(self, total_features, total_classes, bias=True):\n",
    "        \n",
    "        self.total_features = total_features\n",
    "        self.bias = bias\n",
    "        if self.bias==True:\n",
    "            self.total_features += 1\n",
    "\n",
    "        self.total_classes = total_classes\n",
    "        self.clfs = []\n",
    "\n",
    "    def train(self, X_train, Y_train, Transfer_learning=False, epoch=5000, alpha=0.01):\n",
    "\n",
    "        self.epoch = epoch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        if Transfer_learning == True:\n",
    "            self.load_weights()   \n",
    "\n",
    "        # print(\"\\nTrain :: \")\n",
    "\n",
    "        X_train = np.c_[X_train, np.ones(X_train.shape[0])]\n",
    "        m = X_train.shape[0]\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "\n",
    "            new_Y_train = [1 if Y_train[idx] == i else 0 for idx in range(m)]\n",
    "            new_Y_train = np.array(new_Y_train)\n",
    "            new_Y_train = new_Y_train.reshape((-1,))\n",
    "                \n",
    "            clf = LogisticRegression(max_iter=5000).fit(X_train, new_Y_train)\n",
    "            self.clfs.append(clf)\n",
    "                \n",
    "    def test(self, X_test, Y_test):\n",
    "        # print(\"\\nTest :: \")\n",
    "\n",
    "        X_test = np.c_[X_test, np.ones(X_test.shape[0])]\n",
    "        m = X_test.shape[0]\n",
    "\n",
    "        class_percent = []\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):           \n",
    "            \n",
    "            temp_hw_xw = self.clfs[i].predict_proba(X_test)\n",
    "            hw_xw = [temp_hw_xw[i][1] for i in range(len(temp_hw_xw))]\n",
    "            \n",
    "            class_percent.append(hw_xw)\n",
    "\n",
    "        class_percent = np.array(class_percent).T.reshape([m,self.total_classes])\n",
    "        Y_pred = np.argmax(class_percent, axis=1)\n",
    "\n",
    "        true_count = 0\n",
    "        for i in range(m):\n",
    "            if Y_pred[i] == Y_test[i]:\n",
    "                true_count += 1\n",
    "        \n",
    "        accu = true_count/ m\n",
    "        return accu, confusion_matrix(Y_test, Y_pred), classification_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_vs_one_sklearn:\n",
    "    def __init__(self, total_features, total_classes, bias=True):\n",
    "        \n",
    "        self.total_features = total_features\n",
    "        self.bias = bias\n",
    "        if self.bias==True:\n",
    "            self.total_features += 1\n",
    "\n",
    "        self.total_classes = total_classes\n",
    "\n",
    "        count = int((self.total_classes * (self.total_classes-1))/2)\n",
    "        self.clfs = []\n",
    "\n",
    "    def train(self, X_train, Y_train, Transfer_learning=False, epoch=5000, alpha=0.01):\n",
    "\n",
    "        self.epoch = epoch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        if Transfer_learning == True:\n",
    "            self.load_weights()   \n",
    "\n",
    "        # print(\"\\nTrain :: \")\n",
    "\n",
    "        X_train = np.c_[X_train, np.ones(X_train.shape[0])]\n",
    "        total_count = X_test.shape[0]\n",
    "\n",
    "        weight_idx = 0\n",
    "\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "            for j in range(i+1, self.total_classes):\n",
    "\n",
    "                new_X_train = [X_train[idx] for idx in range(total_count) if (Y_train[idx] == i or Y_train[idx] == j)]\n",
    "                new_X_train = np.array(new_X_train)\n",
    "                \n",
    "                m = new_X_train.shape[0]\n",
    "\n",
    "                new_Y_train = [Y_train[idx] for idx in range(total_count) if (Y_train[idx] == i or Y_train[idx] == j)]\n",
    "                 \n",
    "                new_Y_train = [1 if new_Y_train[idx] == i else 0 for idx in range(m)]\n",
    "                new_Y_train = np.array(new_Y_train)\n",
    "                new_Y_train = new_Y_train.reshape((-1,))\n",
    "\n",
    "                clf = LogisticRegression(max_iter=5000).fit(new_X_train, new_Y_train)\n",
    "                self.clfs.append(clf)\n",
    "\n",
    "    def test(self, X_test, Y_test):\n",
    "        # print(\"\\nTest :: \")\n",
    "\n",
    "        X_test = np.c_[X_test, np.ones(X_test.shape[0])]\n",
    "        m = X_test.shape[0]\n",
    "\n",
    "        class_pred = []\n",
    "\n",
    "        weight_idx = 0\n",
    "        for i in tqdm(range(self.total_classes)):\n",
    "            for j in range(i+1, self.total_classes):   \n",
    "                \n",
    "                \n",
    "                hw_xw = self.clfs[weight_idx].predict_proba(X_test)\n",
    "                hw_xw = np.argmax(hw_xw, axis=1)\n",
    "                \n",
    "                onevsone_class_pred = [i if hw_xw[idx]>=0.5 else j for idx in range(m)] \n",
    "                class_pred.append(onevsone_class_pred)\n",
    "\n",
    "                weight_idx += 1\n",
    "                \n",
    "        class_pred = np.array(class_pred)        \n",
    "        Y_pred = stats.mode(class_pred)[0][0]\n",
    "        \n",
    "        true_count = 0\n",
    "        for i in range(m):\n",
    "            if Y_pred[i] == Y_test[i]:\n",
    "                true_count += 1\n",
    "        \n",
    "        accu = true_count/ m\n",
    "        \n",
    "        cm = confusion_matrix(Y_test, Y_pred)\n",
    "        cr = classification_report(Y_test, Y_pred)\n",
    "        \n",
    "        return accu, cm, cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Report accuracy score, Confusion matrix and any other metrics you feel useful and Compare the results - from all the three.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE VS ONE : OWN ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:18<00:00, 19.85s/it]\n"
     ]
    }
   ],
   "source": [
    "one_vs_one_obj = one_vs_one(X_train.shape[1], 10)\n",
    "one_vs_one_obj.train(X_train,Y_train, Transfer_learning=False, epoch=50000, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 141.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7059773828756059\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.84      0.68        58\n",
      "           1       0.80      0.90      0.85        61\n",
      "           2       0.59      0.67      0.63        58\n",
      "           3       0.71      0.65      0.68        57\n",
      "           4       0.86      0.67      0.75        72\n",
      "           5       0.80      0.65      0.72        69\n",
      "           6       0.62      0.40      0.49        62\n",
      "           7       0.87      0.69      0.77        65\n",
      "           8       0.63      0.78      0.70        59\n",
      "           9       0.70      0.83      0.76        58\n",
      "\n",
      "    accuracy                           0.71       619\n",
      "   macro avg       0.71      0.71      0.70       619\n",
      "weighted avg       0.72      0.71      0.70       619\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[49  1  1  0  0  0  1  0  2  4]\n",
      " [ 2 55  1  1  0  0  1  0  1  0]\n",
      " [ 2  1 39  3  2  3  3  0  4  1]\n",
      " [ 1  1  5 37  0  0  5  0  6  2]\n",
      " [ 1  4  4  0 48  2  1  2  7  3]\n",
      " [10  2  5  3  1 45  2  0  0  1]\n",
      " [10  2  5  6  0  5 25  1  1  7]\n",
      " [ 5  2  1  0  2  0  1 45  6  3]\n",
      " [ 0  0  4  2  3  1  0  3 46  0]\n",
      " [ 6  1  1  0  0  0  1  1  0 48]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accu, confusion_matrix, classification_report = one_vs_one_obj.test(X_test, Y_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accu)\n",
    "print(\"\\nclassification_report:\")\n",
    "print(classification_report)\n",
    "print(\"\\nconfusion_matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE VS ONE : Sklearn ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "one_vs_one_sklearn_obj = one_vs_one_sklearn(X_train.shape[1], 10)\n",
    "one_vs_one_sklearn_obj.train(X_train,Y_train, Transfer_learning=False, epoch=50000, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 67.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7366720516962844\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        58\n",
      "           1       0.87      0.90      0.89        61\n",
      "           2       0.49      0.64      0.55        58\n",
      "           3       0.66      0.75      0.70        57\n",
      "           4       0.87      0.76      0.81        72\n",
      "           5       0.75      0.70      0.72        69\n",
      "           6       0.55      0.42      0.48        62\n",
      "           7       0.93      0.78      0.85        65\n",
      "           8       0.73      0.75      0.74        59\n",
      "           9       0.82      0.86      0.84        58\n",
      "\n",
      "    accuracy                           0.74       619\n",
      "   macro avg       0.74      0.74      0.74       619\n",
      "weighted avg       0.74      0.74      0.74       619\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[47  1  2  0  0  1  4  1  1  1]\n",
      " [ 1 55  2  1  0  1  1  0  0  0]\n",
      " [ 0  1 37  5  3  5  3  0  4  0]\n",
      " [ 0  0  3 43  0  0  7  0  4  0]\n",
      " [ 2  3  3  0 55  4  1  0  3  1]\n",
      " [ 7  1  8  3  0 48  2  0  0  0]\n",
      " [ 5  2  9 10  1  4 26  0  0  5]\n",
      " [ 2  0  2  0  1  0  1 51  4  4]\n",
      " [ 0  0  6  3  3  1  1  1 44  0]\n",
      " [ 1  0  4  0  0  0  1  2  0 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accu, confusion_matrix, classification_report = one_vs_one_sklearn_obj.test(X_test, Y_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accu)\n",
    "print(\"\\nclassification_report:\")\n",
    "print(classification_report)\n",
    "print(\"\\nconfusion_matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE VS ALL : OWN ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [29:26<00:00, 176.69s/it]\n"
     ]
    }
   ],
   "source": [
    "one_vs_all_obj = one_vs_all(X_train.shape[1], 10)\n",
    "one_vs_all_obj.train(X_train,Y_train, Transfer_learning=False, epoch=50000, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1100.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7673667205169629\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75        58\n",
      "           1       0.84      0.93      0.88        61\n",
      "           2       0.63      0.64      0.63        58\n",
      "           3       0.70      0.75      0.73        57\n",
      "           4       0.84      0.86      0.85        72\n",
      "           5       0.70      0.75      0.73        69\n",
      "           6       0.68      0.58      0.63        62\n",
      "           7       0.93      0.77      0.84        65\n",
      "           8       0.71      0.66      0.68        59\n",
      "           9       0.95      0.91      0.93        58\n",
      "\n",
      "    accuracy                           0.77       619\n",
      "   macro avg       0.77      0.77      0.77       619\n",
      "weighted avg       0.77      0.77      0.77       619\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[46  0  0  1  1  5  2  1  0  2]\n",
      " [ 1 57  0  1  1  0  1  0  0  0]\n",
      " [ 0  1 37  3  4  4  4  0  5  0]\n",
      " [ 0  2  0 43  1  1  5  0  5  0]\n",
      " [ 2  1  1  0 62  5  1  0  0  0]\n",
      " [ 7  0  2  2  1 52  4  0  1  0]\n",
      " [ 4  4  9  3  0  5 36  0  1  0]\n",
      " [ 3  1  4  0  2  0  0 50  4  1]\n",
      " [ 0  1  6  8  2  1  0  2 39  0]\n",
      " [ 2  1  0  0  0  1  0  1  0 53]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accu, confusion_matrix, classification_report = one_vs_all_obj.test(X_test, Y_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accu)\n",
    "print(\"\\nclassification_report:\")\n",
    "print(classification_report)\n",
    "print(\"\\nconfusion_matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE VS ALL : Sklearn ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "one_vs_all_sklearn_obj = one_vs_all_sklearn(X_train.shape[1], 10)\n",
    "one_vs_all_sklearn_obj.train(X_train,Y_train, Transfer_learning=False, epoch=50000, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 269.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7544426494345718\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        58\n",
      "           1       0.88      0.92      0.90        61\n",
      "           2       0.60      0.67      0.63        58\n",
      "           3       0.68      0.72      0.70        57\n",
      "           4       0.80      0.83      0.82        72\n",
      "           5       0.70      0.70      0.70        69\n",
      "           6       0.67      0.61      0.64        62\n",
      "           7       0.89      0.75      0.82        65\n",
      "           8       0.68      0.66      0.67        59\n",
      "           9       0.95      0.91      0.93        58\n",
      "\n",
      "    accuracy                           0.75       619\n",
      "   macro avg       0.76      0.75      0.75       619\n",
      "weighted avg       0.76      0.75      0.75       619\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[44  0  0  1  2  5  3  1  0  2]\n",
      " [ 1 56  0  1  1  0  2  0  0  0]\n",
      " [ 0  1 39  3  3  5  3  0  4  0]\n",
      " [ 0  1  2 41  1  1  6  1  4  0]\n",
      " [ 2  1  3  0 60  4  0  0  2  0]\n",
      " [ 7  0  2  2  2 48  5  1  2  0]\n",
      " [ 2  4  9  3  0  4 38  0  1  1]\n",
      " [ 3  1  4  0  3  0  0 49  5  0]\n",
      " [ 0  0  6  9  3  1  0  1 39  0]\n",
      " [ 2  0  0  0  0  1  0  2  0 53]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accu, confusion_matrix, classification_report = one_vs_all_sklearn_obj.test(X_test, Y_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accu)\n",
    "print(\"\\nclassification_report:\")\n",
    "print(classification_report)\n",
    "print(\"\\nconfusion_matrix:\")\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}